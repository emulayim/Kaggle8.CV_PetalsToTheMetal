{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3374753b-2ab1-43c6-976b-347283638f90",
   "metadata": {},
   "source": [
    "# Petals to the Metal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649899ad-928c-4e63-8dae-1af01cda12a2",
   "metadata": {},
   "source": [
    "<img src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSpc3PttUQPFJLEvOnv1QEt_50uTTMba6XKVA&s\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49a7ef",
   "metadata": {},
   "source": [
    " \n",
    "## Problemin Tanımı\n",
    "Bu proje, **Petals to the Metal** yarışması kapsamında 104 farklı çiçek türünü sınıflandırmayı amaçlar.\n",
    "## Veri Formatı\n",
    "Veriler **TFRecord** formatındadır. Bu format, büyük veri setlerini verimli bir şekilde okumak için idealdir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c8f41e",
   "metadata": {},
   "source": [
    "# Kütüphaneler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erhan\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(f'TensorFlow Version: {tf.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4c7cf",
   "metadata": {},
   "source": [
    "# TFRecord Okuma Fonksiyonları\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72d9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecords: 16\n",
      "Val TFRecords: 16\n"
     ]
    }
   ],
   "source": [
    "# Veri Yolları\n",
    "DATA_DIR = '../data/tfrecords-jpeg-224x224'\n",
    "TRAIN_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/train/*.tfrec')\n",
    "VAL_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/test/*.tfrec')\n",
    "\n",
    "print(f'Train TFRecords: {len(TRAIN_FILENAMES)}')\n",
    "print(f'Val TFRecords: {len(VAL_FILENAMES)}')\n",
    "\n",
    "# TFRecord Yapısı\n",
    "IMAGE_SIZE = [224, 224]\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = example['class']\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, read from multiple files at once.\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c4752",
   "metadata": {},
   "source": [
    "# Dataset Oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5e6f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasetler hazır.\n"
     ]
    }
   ],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAIN_FILENAMES, labeled=True)\n",
    "    dataset = dataset.repeat() # Sonsuz döngü (steps_per_epoch ile kontrol edilir)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VAL_FILENAMES, labeled=True, ordered=True)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "if len(TRAIN_FILENAMES) > 0:\n",
    "    train_ds = get_training_dataset()\n",
    "    val_ds = get_validation_dataset()\n",
    "    print('Datasetler hazır.')\n",
    "else:\n",
    "    print('HATA: TFRecord dosyaları bulunamadı.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765ece9",
   "metadata": {},
   "source": [
    "# Modelleme (MobileNetV2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd43cb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">133,224</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)                 │         \u001b[38;5;34m133,224\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,391,208</span> (9.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,391,208\u001b[0m (9.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,224</span> (520.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,224\u001b[0m (520.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device('/CPU:0'): # GPU yoksa CPU zorla (veya GPU varsa otomatik kullanır)\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(*IMAGE_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(104, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95eaab5",
   "metadata": {},
   "source": [
    "# Eğitim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c7176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 360ms/step - accuracy: 0.5813 - loss: 1.8161 - val_accuracy: 0.7123 - val_loss: 1.1217\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erhan\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 340ms/step - accuracy: 0.7962 - loss: 0.8161 - val_accuracy: 0.7602 - val_loss: 0.9388\n",
      "Epoch 3/5\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 349ms/step - accuracy: 0.8554 - loss: 0.5759 - val_accuracy: 0.7799 - val_loss: 0.8515\n",
      "Epoch 4/5\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 343ms/step - accuracy: 0.8904 - loss: 0.4420 - val_accuracy: 0.7888 - val_loss: 0.8143\n",
      "Epoch 5/5\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 349ms/step - accuracy: 0.9179 - loss: 0.3520 - val_accuracy: 0.7953 - val_loss: 0.8043\n"
     ]
    }
   ],
   "source": [
    "if len(TRAIN_FILENAMES) > 0:\n",
    "    # TFRecord infinite loop olduğu için steps_per_epoch belirtilmeli\n",
    "    # Tahmini: Dosya sayısı * Dosya başı örnek / Batch size\n",
    "    # Örnek: 12753 training images / 32 = ~398 steps\n",
    "    \n",
    "    steps_per_epoch = 12753 // 32\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=steps_per_epoch\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b1951",
   "metadata": {},
   "source": [
    "# Kaydetme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca94c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved.\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    model.save('../models/best_model.keras')\n",
    "    print('Model Saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ecb4a1-22d6-447d-843b-d6964b7812d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 adet Test dosyası bulundu. Tahmin yapılıyor...\n",
      "Model tahmin üretiyor...\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 273ms/step\n",
      "ID'ler çıkarılıyor...\n",
      "Submission başarıyla kaydedildi: ../outputs/submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252d840db</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1c4736dea</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c37a6f3e9</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00e4f514e</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59d1b6146</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "0  252d840db     67\n",
       "1  1c4736dea     28\n",
       "2  c37a6f3e9     67\n",
       "3  00e4f514e    103\n",
       "4  59d1b6146     70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- DÜZELTİLMİŞ SUBMISSION KODU ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Test TFRecord formatını tanımlayan ve okuyan fonksiyon\n",
    "def read_test_tfrecord(example):\n",
    "    TEST_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, TEST_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum\n",
    "\n",
    "# Test Datasetini Yükleme Fonksiyonu\n",
    "def get_test_dataset(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.map(read_test_tfrecord, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.batch(32) # Batch size\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Dosyaları Bul\n",
    "TEST_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/test/*.tfrec')\n",
    "\n",
    "if len(TEST_FILENAMES) > 0:\n",
    "    print(f'{len(TEST_FILENAMES)} adet Test dosyası bulundu. Tahmin yapılıyor...')\n",
    "\n",
    "    # 1. Test Datasetini Yükle\n",
    "    test_ds = get_test_dataset(TEST_FILENAMES)\n",
    "\n",
    "    # 2. Sadece görüntüleri model için ayır\n",
    "    test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "\n",
    "    # 3. Model ile Tahmin (Bu işlem biraz sürebilir)\n",
    "    print(\"Model tahmin üretiyor...\")\n",
    "    probabilities = model.predict(test_images_ds)\n",
    "    predictions = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "    # 4. ID'leri al (numpy string olarak)\n",
    "    print(\"ID'ler çıkarılıyor...\")\n",
    "    test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "\n",
    "    # ID'leri güvenli bir şekilde listeye çevirelim\n",
    "    test_ids = list(test_ids_ds.as_numpy_iterator())\n",
    "    test_ids = [x.decode('utf-8') for x in test_ids] # Byte string'i normal stringe çevir\n",
    "\n",
    "    # Boyut Kontrolü\n",
    "    if len(test_ids) != len(predictions):\n",
    "        print(f\"UYARI: ID sayısı ({len(test_ids)}) ile tahmin sayısı ({len(predictions)}) uyuşmuyor!\")\n",
    "        # Genellikle dataset.batch() son batch'i eksik bırakabilir veya repeat sorunu olabilir\n",
    "        # Ancak yukarıdaki kodda repeat yok, düzgün çalışmalı.\n",
    "\n",
    "    # 5. DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_ids[:len(predictions)], # Güvenlik için slice\n",
    "        'label': predictions\n",
    "    })\n",
    "\n",
    "    # 6. Kaydet\n",
    "    os.makedirs('../outputs', exist_ok=True)\n",
    "    submission_path = '../outputs/submission.csv'\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "\n",
    "    print(f'Submission başarıyla kaydedildi: {submission_path}')\n",
    "    display(submission.head())\n",
    "\n",
    "else:\n",
    "    print(\"HATA: Test dosyaları bulunamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2948c-a929-4e64-8f81-bb95ad55de1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951ae8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:\\Users\\Erhan\\Documents\\0.YapayZekaKursu\\Projects\\PBL Level2\\Hw.15.BecomeAPro\\8.CV_PetalsToTheMetal\\notebooks\\models\\best_model.keras\n",
      " - C:\\Users\\Erhan\\Documents\\0.YapayZekaKursu\\Projects\\PBL Level2\\Hw.15.BecomeAPro\\8.CV_PetalsToTheMetal\\notebooks\\models\\best_model.weights.h5\n"
     ]
    }
   ],
   "source": [
    "# --- Export model artifacts for Local + HF (recommended: weights) ---\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "keras_path = models_dir / \"best_model.keras\"\n",
    "weights_path = models_dir / \"best_model.weights.h5\"\n",
    "\n",
    "# Save full model (optional on HF; may fail to deserialize)\n",
    "model.save(keras_path)\n",
    "\n",
    "# Save weights-only (recommended; used first in HF)\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", keras_path.resolve())\n",
    "print(\" -\", weights_path.resolve())\n",
    "\n",
    "# Copy to src/ for HF layout (model in src/)\n",
    "src_dir = Path(\"src\")\n",
    "if src_dir.exists():\n",
    "    (src_dir / \"best_model.weights.h5\").write_bytes(weights_path.read_bytes())\n",
    "    # copy .keras too if you want, but not required for HF\n",
    "    try:\n",
    "        (src_dir / \"best_model.keras\").write_bytes(keras_path.read_bytes())\n",
    "    except Exception as e:\n",
    "        print(\"Copy .keras to src failed:\", e)\n",
    "    print(\"Copied weights to src/:\", (src_dir / \"best_model.weights.h5\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb0920-c8c8-4602-bbb6-8263695ac273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c70a3-03e4-4158-b8c1-cf6fbf379cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd52b5-c669-4eb8-897a-b221e31d208e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d376d88-dd07-49df-8f14-c7420e0b3e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
